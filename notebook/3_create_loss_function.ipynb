{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ここて行う処理\n",
    "- jaccard係数を用いてmacthingを行う\n",
    "    - 係数計算は面積のみに注目していて、クラス情報は無視している感じ\n",
    "- Hard Negative Miningを行って、data imbalance問題を対応\n",
    "- SmoothL1Loss関数を実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match 関数\n",
    "- 教師データ : loc_t, conf_t_labelを用意していく\n",
    "- 教師データ作成のため？ X (そもそも最初から正解ラベルがあるからね)\n",
    "- loss関数計算のために、計算結果が正しいものの集計？  O"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hard Negative Mining\n",
    "- Negative DBoxに分類されたDBoxのうち、学習に使用するDBoxの数を絞る操作\n",
    "- Locationに関する損失値はPositive DBoxにのみ計算できる\n",
    "    - Negative DBoxは背景をさしているため、BBoxを持たない\n",
    "- Negative DBoxとPositive DBoxデータのimbalance問題を解決する\n",
    "- Negative Samplingで優先するDBox\n",
    "    - ラベル予測がうまく行っていないDBoxを優先"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SmoothL1Loss関数と交差エントロピー誤差関数\n",
    " - matchとHard Negative Mining操作により、損失を計算する際に使用する教師データと予測結果が求まる\n",
    " - 上の結果を用いて損失関数の損失値を計算する\n",
    " - この損失関数は、予測位置と正解位置の間に差が大きい場合、損失値が多くなり、ネットワーク学習が不安定になることを抑えるため、設計されている\n",
    " - ![位置情報の損失関数](../data/loc_loss.png)\n",
    " \n",
    " - SmoothL1Loss関数 : 位置情報損失関数 (回帰問題に落とされるため)\n",
    " - 交差エントロピー誤差関数 : 多クラス分類問題"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from match import match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 損失関数を実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SSD_Loss(nn.Module):\n",
    "    def __init__(self, jaccard_thresh=0.5, negpos_ratio=3, device='cpu'):\n",
    "        super(SSD_Loss, self).__init__()\n",
    "        self.negpos_ratio = negpos_ratio\n",
    "        self.device = device\n",
    "    \n",
    "    def forward(self, predictions, targets):\n",
    "        \"\"\"\n",
    "        predictions : (location, confidence, self.dbox_list)\n",
    "        targets: [num_batch, num_object, 5]\n",
    "        \"\"\"\n",
    "        #  locations=torch.Size([num_batch, 8732, 4])\n",
    "        # confidences=torch.Size([num_batch, 8732, 21])\n",
    "        # dboxes=torch.Size [8732,4])\n",
    "        locations, confidences, dboxes = predictions\n",
    "        \n",
    "        # locations : [num_batch, 8732, 4]\n",
    "        # confidences : [num_batch, 8732, 21]\n",
    "        num_batch = locations.size(0)\n",
    "        num_dbox = locations.size(1)\n",
    "        num_classes = confidences.size(2)\n",
    "        \n",
    "        # 正解ラベル : おそらくone hot vectorが格納されている\n",
    "        # .toは該当deviceに必要なデータタイプにデータを変換してくれる\n",
    "        pred_labels = torch.LongTensor(num_batch, num_dbox).to(self.device)\n",
    "        pred_locations = torch.Tensor(num_batch, num_dbox, 4).to(self.device)\n",
    "        \n",
    "        for idx in range(num_batch):\n",
    "            # BBoxの位置情報\n",
    "            answers = targets[idx][:, :-1].to(self.device)\n",
    "            # 物体ラベル情報\n",
    "            labels = targets[idx][:, -1].to(self.device)\n",
    "            \n",
    "            dbox = dboxes.to(self.device)\n",
    "            \n",
    "            # 座標変換を行う時に係数である\n",
    "            variance = [0.1, 0.2]\n",
    "            \n",
    "            # matcth関数は予測結果が正解かどうかを判定していく\n",
    "            # 方法:\n",
    "            #     - BBoxとjaccard係数が一定以上を持つDBoxは当たったことにする\n",
    "            #      (DBox_location <= BBox_location, DBox_label=BBox_obj_id)\n",
    "            #     - jaccard係数が閾値以下の場合、バックグラウンドが当たったとして、DBox_labelを\n",
    "            #       背景idにする。ただ、この場合、位置情報は持たないし、後のloss計算でも使わない\n",
    "            match(self.jaccard_thresh, answers, dbox, variance, labels, pred_locations, pred_labels, idx)\n",
    "            \n",
    "        # location loss値を計算 : SmoothL1Loss\n",
    "        # positive結果のlocationのみを使う\n",
    "        # label = 0 は背景に当たるため\n",
    "        # torch.Size([num_batch, 8732])\n",
    "        pos_mask = pred_labels  > 0\n",
    "        \n",
    "        pos_idx = pos_mask.unsqueeze(pos_mask.dim()).expand_as(locations)\n",
    "        \n",
    "        pos_locations = locations[pos_idx].view(-1, 4)\n",
    "        pos_labels = pred_labels[pos_idx].view(-1, 4)\n",
    "        \n",
    "        loss_location = F.smooth_l1_loss(pos_locations, pos_labels, reduction='sum')\n",
    "        \n",
    "        #  labels loss値を計算 : クロスエントロピー\n",
    "        batch_confidence = confidences.view(-1, num_classes)\n",
    "        \n",
    "        loss_confidence = F.cross_entropy(batch_confidence, pred_labels.view(-1), reduction='none')\n",
    "        \n",
    "        ##\n",
    "        # Hard Negative Mining処理\n",
    "        ##\n",
    "        num_pos = pos_mask.long().sum(1, keepdim=True)\n",
    "        loss_confidence = loss_confidence.view(num_batch, -1)  # [num_batch, 8732]\n",
    "        # 検知に成功したDBoxのloss値は0に設定\n",
    "        loss_confidence[pos_mask] = 0\n",
    "        \n",
    "        # この部分はまだちょっとわかっていない\n",
    "        _, loss_idx = loss_c.sort(1, descending=True)\n",
    "        _, idx_rank = loss_idx.sort(1)\n",
    "        \n",
    "        num_neg = torch.clamp(num_pos*self.negpos_ratio, max=num_box)\n",
    "        # 学習をよくするために損失値が大きいNegative DBoxを優先的にとる\n",
    "        # 上のloss_idx、idx_rankはこの処理のために必要\n",
    "        neg_mask = idx_rank < (num_neg).expand_as(idx_rank)\n",
    "        \n",
    "        # Hard Negative MiningでとってきたNegative DBoxを抽出\n",
    "        pos_idx_mask = pos_mask.unsqueeze(2).expand_as(confidences)\n",
    "        neg_idx_mask = neg_mask.unsqueeze(2).expand_as(confidences)\n",
    "\n",
    "        # [num_pos+num_nge, num_classes]\n",
    "        # Downsamplingの結果のみを使ってloss値を計算\n",
    "        confidence_final = confidences[(pos_idx_mask+neg_idx_mask).gt(0)].view(-1, num_classes)\n",
    "        labels_final = pred_labels[(pos_mask+neg_mask).gt(0)]\n",
    "        \n",
    "        loss_confidence = F.cross_entropy(confidence_final, labels_final, reduction='sum')\n",
    "        \n",
    "        N = num_pos.sum()\n",
    "        loss_location /= N\n",
    "        loss_confidence /= N\n",
    "        \n",
    "        return loss_location, loss_confidence"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
